{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d542c4fc",
   "metadata": {},
   "source": [
    "# #  ML Project Template\n",
    "# \n",
    "# Reusable workflow:\n",
    "# 1. Imports & config\n",
    "# 2. Load data\n",
    "# 3. Inspect & clean\n",
    "# 4. EDA (visualization)\n",
    "# 5. Preprocessing & feature engineering\n",
    "# 6. Train/test split\n",
    "# 7. Model training\n",
    "# 8. Evaluation & residual analysis\n",
    "# 9. Cross-validation\n",
    "# 10. Iteration hooks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTS & CONFIG\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot style (optional)\n",
    "plt.style.use(\"default\")\n",
    "sns.set_theme()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ## 2. Load Data\n",
    "# - Adjust file path and loader as needed.\n",
    "# - This cell is the only one that should be very dataset-specific.\n",
    "\n",
    "# 2. LOAD DATA\n",
    "\n",
    "# TODO: Change this to your actual data file\n",
    "DATA_PATH = \"AmesHousing.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Basic Inspection & Sanity Checks\n",
    "# - `info`, `describe`, missing values\n",
    "# - Categorical vs numeric overview\n",
    "\n",
    "# 3. INSPECT DATA\n",
    "\n",
    "print(\"=== INFO ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== DESCRIBE (NUMERIC) ===\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES PER COLUMN ===\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\n=== UNIQUE VALUES PER COLUMN ===\")\n",
    "print(df.nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69055b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Quick EDA: Distributions & Outliers\n",
    "# - Histograms\n",
    "# - Boxplots\n",
    "# - Basic skewness check\n",
    "#\n",
    "# NOTE: Adjust `numeric_cols` list to your dataset.\n",
    "# 4. EDA - DISTRIBUTIONS\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Histograms\n",
    "df[numeric_cols].hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for numeric columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "df[numeric_cols].boxplot()\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplots of Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Skewness\n",
    "print(\"\\n=== SKEWNESS ===\")\n",
    "print(df[numeric_cols].skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Relationships: Scatter, Correlation, Pairplot\n",
    "# - Use this cell when dataset is not huge.\n",
    "# - Adjust `key_features` to a smaller subset if needed.\n",
    "# 5. EDA - RELATIONSHIPS\n",
    "\n",
    "# TODO: Set your target column\n",
    "TARGET_COL = \"SalePrice\" #This will always be Y, or desired prediction\n",
    "\n",
    "# Choose a few key features for scatter / pairplot\n",
    "key_features = [col for col in numeric_cols if col != TARGET_COL][:4]\n",
    "print(\"Key features for pairplot:\", key_features)\n",
    "\n",
    "if TARGET_COL in df.columns:\n",
    "    # Simple scatter with target if numeric\n",
    "    if np.issubdtype(df[TARGET_COL].dtype, np.number):\n",
    "        for col in key_features:\n",
    "            plt.figure()\n",
    "            plt.scatter(df[col], df[TARGET_COL], alpha=0.5)\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel(TARGET_COL)\n",
    "            plt.title(f\"{col} vs {TARGET_COL}\")\n",
    "            plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "corr = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot (small feature subset)\n",
    "if len(key_features) > 1:\n",
    "    sns.pairplot(df[key_features + [TARGET_COL]].dropna(), corner=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41ddb319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Mas_Vnr_Area     23\n",
      "BsmtFin_SF_2      1\n",
      "Bsmt_Unf_SF       1\n",
      "Total_Bsmt_SF     1\n",
      "BsmtFin_SF_1      1\n",
      "Garage_Cars       1\n",
      "Garage_Area       1\n",
      "Electrical        1\n",
      "Lot_Area          0\n",
      "PID               0\n",
      "MS_SubClass       0\n",
      "MS_Zoning         0\n",
      "Order             0\n",
      "Land_Slope        0\n",
      "Neighborhood      0\n",
      "Condition_2       0\n",
      "Condition_1       0\n",
      "House_Style       0\n",
      "Overall_Qual      0\n",
      "Overall_Cond      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ## 6. Handle Missing Data & Obvious Cleaning\n",
    "# - Light-touch template. Customize as needed.\n",
    "# - Options: drop rows, impute, custom rules.\n",
    "\n",
    "# 6. CLEANING\n",
    "\n",
    "# Standardize column names to snake_case\n",
    "import re\n",
    "\n",
    "def to_snake(col):\n",
    "    # Replace spaces and hyphens with underscore\n",
    "    col = re.sub(r\"[ -]+\", \"_\", col)\n",
    "\n",
    "    # Insert underscore before capital letters (except first)\n",
    "    # col = re.sub(r\"(?<!^)([A-Z])\", r\"_\\1\", col)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    # col = col.lower()\n",
    "\n",
    "    return col\n",
    "\n",
    "df.columns = [to_snake(col) for col in df.columns]\n",
    "\n",
    "# print(\"Updated column names:\")\n",
    "# print(df.columns.tolist())\n",
    "\n",
    "# Identify missing data\n",
    "missing_summary = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435646a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d42daad7",
   "metadata": {},
   "source": [
    "6.1 DROP ROWS ONLY WHEN NECESSARY\n",
    "\n",
    "Only drop:\n",
    "\n",
    "rows missing the target\n",
    "\n",
    "rows that are mostly empty\n",
    "\n",
    "rows containing invalid data (e.g., negative square footage)\n",
    "\n",
    "6.2 IMPUTE NUMERIC COLUMNS\n",
    "\n",
    "Why median?\n",
    "\n",
    "Median is robust to outliers\n",
    "Mean gets distorted badly.\n",
    "\n",
    "6.3 IMPUTE CATEGORICAL COLUMNS\n",
    "\n",
    "Most common strategies:\n",
    "\n",
    "Mode (most frequent value)\n",
    "\n",
    "Works well when missing data is small.\n",
    "\n",
    "Binary flag existence, set missing to None.  Use smart logic to determine if data was missing or just entered incorrectly.\n",
    "This is unique to each Category.  Use the information you have.\n",
    "\n",
    "A missing value indicator can be extremely predictive.\n",
    "\n",
    "Example:\n",
    "\n",
    "A missing basement quality often means “no basement”\n",
    "\n",
    "A missing fireplace quality often means “no fireplace”\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col + \"_was_missing\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n",
    "This adds search-light columns that say:\n",
    "\n",
    "1 = was missing\n",
    "\n",
    "0 = was present\n",
    "\n",
    "\n",
    "Will oneHotOff or ordinal later.  This is all data cleaning.\n",
    "\n",
    "6.5 CLEAN OBVIOUS BAD VALUES\n",
    "\n",
    "Examples:\n",
    "\n",
    "Square footage cannot be negative.\n",
    "\n",
    "Lot area cannot be zero.\n",
    "\n",
    "Quality ratings must be one of the known categories.\n",
    "\n",
    "df['Gr_Liv_Area'] = df['Gr_Liv_Area'].clip(lower=0)\n",
    "\n",
    "6.6 NORMALIZE TEXT DATA (easy mistakes)\n",
    "\n",
    "Common cleaning:\n",
    "\n",
    "df[col] = df[col].str.strip().str.lower()\n",
    "df[col] = df[col].str.replace('-', '_')\n",
    "\n",
    "\n",
    "Cleaning avoids:\n",
    "\n",
    "duplicates (“Ex”, “ex”, “ EX”)\n",
    "\n",
    "weird Unicode\n",
    "\n",
    "inconsistent punctuation\n",
    "\n",
    "6.8 Final Check: Data Must Be Fully Clean\n",
    "\n",
    "After imputation:\n",
    "\n",
    "print(df.isna().sum().sum())   # should be 0\n",
    "\n",
    "If NOT zero → model will crash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if there is a positive correlation between Lot_Area and Lot_Frontage\n",
    "\n",
    "sns.scatterplot(x=df[\"Lot_Area\"], y=df[\"Lot_Frontage\"])\n",
    "plt.xscale(\"log\")  # because Lot_Area spans huge ranges\n",
    "plt.show()\n",
    "\n",
    "df[[\"Lot_Area\", \"Lot_Frontage\"]].corr()\n",
    "\n",
    "# There is, so lets impute missing Lot_Frontage values based on Lot_Area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPUTE LOT_FRONTAGE USING LOT_AREA RATIO\n",
    "# ========================================\n",
    "\n",
    "print(\"Missing Lot_Frontage BEFORE:\", df[\"Lot_Frontage\"].isna().sum())\n",
    "\n",
    "# 1. Create missingness flag (always useful for models)\n",
    "df[\"Lot_Frontage_missing\"] = df[\"Lot_Frontage\"].isna().astype(int)\n",
    "\n",
    "# 2. Compute typical depth = Lot_Area / Lot_Frontage\n",
    "#    (only using rows where both values exist)\n",
    "valid = df.dropna(subset=[\"Lot_Frontage\", \"Lot_Area\"])\n",
    "\n",
    "# Avoid divide-by-zero rows\n",
    "valid = valid[valid[\"Lot_Frontage\"] > 0]\n",
    "\n",
    "median_depth = (valid[\"Lot_Area\"] / valid[\"Lot_Frontage\"]).median()\n",
    "print(\"Median lot depth (Lot_Area / Lot_Frontage):\", median_depth)\n",
    "\n",
    "# 3. Impute missing frontage as Lot_Area / median_depth\n",
    "mask_missing = df[\"Lot_Frontage\"].isna()\n",
    "\n",
    "df.loc[mask_missing, \"Lot_Frontage\"] = (\n",
    "    df.loc[mask_missing, \"Lot_Area\"] / median_depth\n",
    ")\n",
    "\n",
    "print(\"Missing Lot_Frontage AFTER:\", df[\"Lot_Frontage\"].isna().sum())\n",
    "print(\"Imputed Lot_Frontage for\", mask_missing.sum(), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7171486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle pool weirdness\n",
    "\n",
    "print(df[\"Pool_QC\"].value_counts(dropna=False))\n",
    "print(df[\"Pool_Area\"].describe())\n",
    "# Impute Pool_QC based on Pool_Area\n",
    "df[\"Has_Pool\"] = (\n",
    "    (df[\"Pool_Area\"] > 0) | df[\"Pool_QC\"].notna()\n",
    ").astype(int)\n",
    "# For rows where we believe there is NO pool, set quality to \"None\"\n",
    "no_pool_mask = (df[\"Has_Pool\"] == 0) & (df[\"Pool_QC\"].isna())\n",
    "df.loc[no_pool_mask, \"Pool_QC\"] = \"None\"\n",
    "print(\"After imputation of Pool_QC based on Pool_Area:\")\n",
    "print(df[\"Pool_QC\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Hassing Misc_Feature, add Boolean flag column\n",
    "# Replace NA with None, strip whitespace\n",
    "\n",
    "print(df[\"Misc_Feature\"].value_counts(dropna=False))\n",
    "df[\"Has_Misc_Feature\"] = df[\"Misc_Feature\"].notna().astype(int)\n",
    "df[\"Misc_Feature\"] = df[\"Misc_Feature\"].fillna(\"None\")\n",
    "df[\"Misc_Feature\"] = df[\"Misc_Feature\"].str.strip()\n",
    "df[\"Misc_Feature\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Alley\n",
    "print(df[\"Alley\"].value_counts(dropna=False))\n",
    "# ============================\n",
    "# CLEANING: Alley\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Alley\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Boolean flag—does the house have alley access?\n",
    "df[\"Has_Alley\"] = df[\"Alley\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NA with explicit category \"None\"\n",
    "df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace just in case\n",
    "df[\"Alley\"] = df[\"Alley\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Alley\"].value_counts())\n",
    "print(df[\"Has_Alley\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ebe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CLEANING: Fence\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Fence\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Feature flag — does the house have ANY fenced enclosure?\n",
    "df[\"Has_Fence\"] = df[\"Fence\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NaN with explicit category \"None\"\n",
    "df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace (always safe)\n",
    "df[\"Fence\"] = df[\"Fence\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Fence\"].value_counts())\n",
    "print(df[\"Has_Fence\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13183823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CLEANING: Mas_Vnr_Type\n",
    "# ============================\n",
    "\n",
    "# Ai defiiniely help with this one.  Didn't really think to include Masonry Veneer\n",
    "# area as a qualifier for what the data meant.  If 0, NA means None.  If >0, NA means Unknown.\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Feature flag — does the house have a masonry veneer?\n",
    "df[\"Has_Masonry_Veneer\"] = (df[\"Mas_Vnr_Area\"] > 0).astype(int)\n",
    "\n",
    "# 2. Case 1: Area == 0 → definitely None\n",
    "none_mask = (df[\"Mas_Vnr_Area\"] == 0) & (df[\"Mas_Vnr_Type\"].isna())\n",
    "df.loc[none_mask, \"Mas_Vnr_Type\"] = \"None\"\n",
    "\n",
    "# 3. Case 2: Area > 0 but type is missing → ambiguous → \"Unknown\"\n",
    "unknown_mask = (df[\"Mas_Vnr_Area\"] > 0) & (df[\"Mas_Vnr_Type\"].isna())\n",
    "df.loc[unknown_mask, \"Mas_Vnr_Type\"] = \"Unknown\"\n",
    "\n",
    "# 4. Clean whitespace\n",
    "df[\"Mas_Vnr_Type\"] = df[\"Mas_Vnr_Type\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts())\n",
    "print(df[\"Has_Masonry_Veneer\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CLEANING: Fireplace_Qu\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Fireplace_Qu\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Boolean flag — does the house have a fireplace?\n",
    "df[\"Has_Fireplace\"] = df[\"Fireplace_Qu\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NA with explicit category \"None\"\n",
    "df[\"Fireplace_Qu\"] = df[\"Fireplace_Qu\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace\n",
    "df[\"Fireplace_Qu\"] = df[\"Fireplace_Qu\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Fireplace_Qu\"].value_counts())\n",
    "print(df[\"Has_Fireplace\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Garage\n",
    "#1.  Intelligently determine the boolean flag for Has_Garage based on available data\n",
    "df[\"Has_Garage\"] = (\n",
    "    (df[\"Garage_Cars\"] > 0) | \n",
    "    (df[\"Garage_Area\"] > 0) | \n",
    "    (df[\"Garage_Type\"].notna())\n",
    ").astype(int)\n",
    "#2 Use the boolean flag to impute missing Garage_Type values\n",
    "# If no garage: type is None\n",
    "df.loc[(df[\"Has_Garage\"] == 0) & (df[\"Garage_Type\"].isna()), \"Garage_Type\"] = \"None\"\n",
    "\n",
    "# If garage exists but type missing: mark Unknown\n",
    "df.loc[(df[\"Has_Garage\"] == 1) & (df[\"Garage_Type\"].isna()), \"Garage_Type\"] = \"Unknown\"\n",
    "print(\"After handling Garage_Type:\")\n",
    "print(df[\"Garage_Type\"].value_counts(dropna=False))\n",
    "\n",
    "#3 Use the boolean flag to impute other Garage-related categorical columns\n",
    "garage_cols = [\"Garage_Finish\", \"Garage_Qual\", \"Garage_Cond\"]\n",
    "\n",
    "for col in garage_cols:\n",
    "    # No garage → None\n",
    "    df.loc[(df[\"Has_Garage\"] == 0) & (df[col].isna()), col] = \"None\"\n",
    "\n",
    "    # Garage exists but value missing → Unknown\n",
    "    df.loc[(df[\"Has_Garage\"] == 1) & (df[col].isna()), col] = \"Unknown\"\n",
    "\n",
    "#4 Deal with Garage_Yr_Blt.  Assume same year if possible.\n",
    "\n",
    "df.loc[df[\"Has_Garage\"] == 0, \"Garage_Yr_Blt\"] = 0\n",
    "\n",
    "df.loc[(df[\"Has_Garage\"] == 1) & (df[\"Garage_Yr_Blt\"].isna()), \"Garage_Yr_Blt\"] = \\\n",
    "    df.loc[(df[\"Has_Garage\"] == 1), \"Year_Built\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d21bab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# CLEANING: Basement block\n",
    "# ==================================\n",
    "\n",
    "# 1. Does the house have a basement?\n",
    "df[\"Has_Basement\"] = (\n",
    "    (df[\"Total_Bsmt_SF\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_1\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_2\"] > 0) |\n",
    "    (df[\"Bsmt_Unf_SF\"] > 0)\n",
    ").astype(int)\n",
    "\n",
    "# 2. Finished vs Unfinished booleans\n",
    "df[\"Has_Finished_Basement\"] = (\n",
    "    (df[\"BsmtFin_SF_1\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_2\"] > 0)\n",
    ").astype(int)\n",
    "\n",
    "df[\"Has_Unfinished_Basement\"] = (df[\"Bsmt_Unf_SF\"] > 0).astype(int)\n",
    "\n",
    "# 3. Clean the categorical basement columns\n",
    "basement_cols = [\n",
    "    \"Bsmt_Qual\", \"Bsmt_Cond\", \"BsmtFin_Type_1\", \"BsmtFin_Type_2\"\n",
    "]\n",
    "\n",
    "# 3a. If no basement → fill with \"None\"\n",
    "for col in basement_cols:\n",
    "    df.loc[(df[\"Has_Basement\"] == 0) & (df[col].isna()), col] = \"None\"\n",
    "\n",
    "# 3b. If basement exists but NA → \"Unknown\"\n",
    "for col in basement_cols:\n",
    "    df.loc[(df[\"Has_Basement\"] == 1) & (df[col].isna()), col] = \"Unknown\"\n",
    "\n",
    "# 4. Special cleaning for Bsmt_Exposure\n",
    "# NA means \"No exposure\" IF the house has a basement\n",
    "df.loc[(df[\"Has_Basement\"] == 0), \"Bsmt_Exposure\"] = \"None\"\n",
    "df.loc[(df[\"Has_Basement\"] == 1) & (df[\"Bsmt_Exposure\"].isna()), \"Bsmt_Exposure\"] = \"No\"\n",
    "\n",
    "# 5. Strip whitespace (safety)\n",
    "for col in [\"Bsmt_Qual\", \"Bsmt_Cond\", \"BsmtFin_Type_1\", \"BsmtFin_Type_2\", \"Bsmt_Exposure\"]:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# 6. Impute missing numeric basement columns with 0 (no basement area)\n",
    "# 6. Numeric basement fields: set to 0 when no basement, and clean rare NaNs\n",
    "\n",
    "numeric_basement_cols = [\n",
    "    \"Total_Bsmt_SF\",\n",
    "    \"BsmtFin_SF_1\",\n",
    "    \"BsmtFin_SF_2\",\n",
    "    \"Bsmt_Unf_SF\",\n",
    "    \"Bsmt_Full_Bath\",\n",
    "    \"Bsmt_Half_Bath\",\n",
    "]\n",
    "\n",
    "# Case 1: No basement → all numeric basement fields must be 0\n",
    "for col in numeric_basement_cols:\n",
    "    df.loc[df[\"Has_Basement\"] == 0, col] = 0\n",
    "\n",
    "# Case 2: Basement exists but value is NaN → assume 0 (no area / no bath recorded)\n",
    "for col in numeric_basement_cols:\n",
    "    df.loc[(df[\"Has_Basement\"] == 1) & (df[col].isna()), col] = 0\n",
    "\n",
    "# (Optional) cast to int where appropriate\n",
    "int_basement_cols = [\"Bsmt_Full_Bath\", \"Bsmt_Half_Bath\"]\n",
    "for col in int_basement_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a588c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (type):\n",
      "Mas_Vnr_Type\n",
      "None       1745\n",
      "BrkFace     880\n",
      "Stone       249\n",
      "BrkCmn       25\n",
      "nan          23\n",
      "Unknown       7\n",
      "CBlock        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Before (area NaNs): 23\n",
      "\n",
      "After (type):\n",
      "Mas_Vnr_Type\n",
      "None       1745\n",
      "BrkFace     880\n",
      "Stone       249\n",
      "BrkCmn       25\n",
      "nan          23\n",
      "Unknown       7\n",
      "CBlock        1\n",
      "Name: count, dtype: int64\n",
      "After (area NaNs): 23\n",
      "Has_Masonry_Veneer value counts:\n",
      "Has_Masonry_Veneer\n",
      "0    1771\n",
      "1    1159\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# CLEANING: Mas_Vnr_Type + Mas_Vnr_Area\n",
    "# ============================\n",
    "\n",
    "print(\"Before (type):\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts(dropna=False))\n",
    "print(\"Before (area NaNs):\", df[\"Mas_Vnr_Area\"].isna().sum())\n",
    "\n",
    "# 1. If area > 0 AND type is NaN → there IS veneer, but type unknown\n",
    "unknown_mask = (df[\"Mas_Vnr_Area\"] > 0) & (df[\"Mas_Vnr_Type\"].isna())\n",
    "df.loc[unknown_mask, \"Mas_Vnr_Type\"] = \"Unknown\"\n",
    "\n",
    "# 2. All remaining NaN types → treat as \"None\" (no veneer)\n",
    "df.loc[df[\"Mas_Vnr_Type\"].isna(), \"Mas_Vnr_Type\"] = \"None\"\n",
    "\n",
    "# 3. Clean whitespace\n",
    "df[\"Mas_Vnr_Type\"] = df[\"Mas_Vnr_Type\"].astype(str).str.strip()\n",
    "\n",
    "# 4. Boolean: has masonry veneer? (now based on cleaned type)\n",
    "df[\"Has_Masonry_Veneer\"] = (df[\"Mas_Vnr_Type\"] != \"None\").astype(int)\n",
    "\n",
    "# 5. Fix Mas_Vnr_Area:\n",
    "#    Case A: no veneer → area must be 0\n",
    "none_area_mask = (df[\"Has_Masonry_Veneer\"] == 0) & (df[\"Mas_Vnr_Area\"].isna())\n",
    "df.loc[none_area_mask, \"Mas_Vnr_Area\"] = 0\n",
    "\n",
    "#    Case B: veneer present but area NaN → fill with median for that type\n",
    "for t in df[\"Mas_Vnr_Type\"].unique():\n",
    "    type_mask = (df[\"Mas_Vnr_Type\"] == t) & (df[\"Mas_Vnr_Area\"].isna())\n",
    "    if type_mask.any():\n",
    "        median_area = df.loc[df[\"Mas_Vnr_Type\"] == t, \"Mas_Vnr_Area\"].median()\n",
    "        df.loc[type_mask, \"Mas_Vnr_Area\"] = median_area\n",
    "\n",
    "print(\"\\nAfter (type):\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts())\n",
    "print(\"After (area NaNs):\", df[\"Mas_Vnr_Area\"].isna().sum())\n",
    "print(\"Has_Masonry_Veneer value counts:\")\n",
    "print(df[\"Has_Masonry_Veneer\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e30de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# CLEANING: Bsmt_Full_Bath & Bsmt_Half_Bath\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Bsmt_Full_Bath\"].value_counts(dropna=False))\n",
    "print(df[\"Bsmt_Half_Bath\"].value_counts(dropna=False))\n",
    "\n",
    "# Full bath:\n",
    "df.loc[df[\"Bsmt_Full_Bath\"].isna(), \"Bsmt_Full_Bath\"] = 0\n",
    "\n",
    "# Half bath:\n",
    "df.loc[df[\"Bsmt_Half_Bath\"].isna(), \"Bsmt_Half_Bath\"] = 0\n",
    "\n",
    "# (Optional sanity: cast to integer)\n",
    "df[\"Bsmt_Full_Bath\"] = df[\"Bsmt_Full_Bath\"].astype(int)\n",
    "df[\"Bsmt_Half_Bath\"] = df[\"Bsmt_Half_Bath\"].astype(int)\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Bsmt_Full_Bath\"].value_counts())\n",
    "print(df[\"Bsmt_Half_Bath\"].value_counts())\n",
    "\n",
    "df[\"Bsmt_Total_Baths\"] = df[\"Bsmt_Full_Bath\"] + 0.5 * df[\"Bsmt_Half_Bath\"]\n",
    "print(\"Created Bsmt_Total_Baths feature.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85cbe34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: Mas_Vnr_Area\n",
      "Missing count: 23\n",
      "Row indices: [55, 484, 517, 538, 867, 1095, 1119, 1122, 1127, 1184, 1454, 1727, 1751, 1783, 1799, 1839, 1840, 2229, 2260, 2382, 2392, 2455, 2823]\n",
      "\n",
      "Column: Garage_Cars\n",
      "Missing count: 1\n",
      "Row indices: [2236]\n",
      "\n",
      "Column: Garage_Area\n",
      "Missing count: 1\n",
      "Row indices: [2236]\n",
      "Missing values per column:\n",
      "Mas_Vnr_Area    23\n",
      "Garage_Cars      1\n",
      "Garage_Area      1\n",
      "PID              0\n",
      "MS_SubClass      0\n",
      "Lot_Area         0\n",
      "Street           0\n",
      "Alley            0\n",
      "Lot_Shape        0\n",
      "Land_Contour     0\n",
      "Utilities        0\n",
      "MS_Zoning        0\n",
      "Order            0\n",
      "Land_Slope       0\n",
      "Neighborhood     0\n",
      "Condition_2      0\n",
      "Condition_1      0\n",
      "House_Style      0\n",
      "Overall_Qual     0\n",
      "Overall_Cond     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# SHOW ROW INDICES FOR RARE MISSING VALUES\n",
    "# (columns with fewer than 5 missing entries)\n",
    "# ==========================================\n",
    "\n",
    "for col in df.columns:\n",
    "    missing_idx = df[df[col].isna()].index\n",
    "    \n",
    "    if 0 < len(missing_idx) < 24:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"Missing count: {len(missing_idx)}\")\n",
    "        print(f\"Row indices: {list(missing_idx)}\")\n",
    "\n",
    "missing_summary = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary.head(20))\n",
    "# ==========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a759d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After handling Electrical:\n",
      "Electrical\n",
      "SBrkr    2683\n",
      "FuseA     188\n",
      "FuseF      50\n",
      "FuseP       8\n",
      "Mix         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Filling row 1577 with missing electrical as standard breaker, because home was built in 2008 and Iowa building code likely required it\n",
    "df.loc[df[\"Electrical\"].isna(), \"Electrical\"] = \"SBrkr\"\n",
    "print(\"After handling Electrical:\")\n",
    "print(df[\"Electrical\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 7. Define Features (X) and Target (y)\n",
    "# - Select feature columns explicitly.\n",
    "# - Split numeric vs categorical.\n",
    "# - This is where you decide what the model can \"see.\"\n",
    "\n",
    "# 7. FEATURE / TARGET SETUP\n",
    "\n",
    "# TODO: decide which columns are features\n",
    "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 8. Preprocessing: Encoding & Scaling\n",
    "# - Numeric: StandardScaler\n",
    "# - Categorical: OneHotEncoder\n",
    "# - All wrapped in a ColumnTransformer + Pipeline\n",
    "\n",
    "# 8. PREPROCESSOR\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example model: Linear Regression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Full pipeline: preprocessing + model\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", regressor)\n",
    "])\n",
    "\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 9. Train/Test Split\n",
    "# - Typical split: 80/20 or 70/30.\n",
    "# - Randomized with fixed `random_state` for reproducibility.\n",
    "\n",
    "# 9. TRAIN / TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Train the Model\n",
    "# - Fit the pipeline on training data.\n",
    "# 10. TRAIN MODEL\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 11. Evaluation on Train and Test Sets\n",
    "# - R², MAE, RMSE\n",
    "# - Compare train vs test for over/underfitting.\n",
    "\n",
    "# 11. EVALUATION\n",
    "\n",
    "def regression_metrics(y_true, y_pred, label=\"\"):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print()\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "regression_metrics(y_train, y_pred_train, label=\"Train\")\n",
    "regression_metrics(y_test, y_pred_test, label=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 12. Residual Analysis (Train Set)\n",
    "# - Check assumptions: linearity, homoscedasticity, normality.\n",
    "# %%\n",
    "# 12. RESIDUALS\n",
    "\n",
    "train_residuals = y_train - y_pred_train\n",
    "\n",
    "# Residuals vs predicted\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_pred_train, train_residuals, alpha=0.5)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted (Train)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predicted (Train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Residuals Distribution (Train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 13. Cross Validation (Optional but Recommended)\n",
    "# - K-Fold CV for more robust estimation.\n",
    "# - Uses the full pipeline (preprocess + model) inside CV.\n",
    "\n",
    "# 13. CROSS VALIDATION\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
    "\n",
    "print(\"CV R² scores:\", cv_scores)\n",
    "print(\"CV R² mean:\", cv_scores.mean())\n",
    "print(\"CV R² std:\", cv_scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acaac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 14. TODO: Iteration Hooks\n",
    "# - If metrics are poor:\n",
    "#   - Revisit EDA, transformations, feature engineering.\n",
    "#   - Consider:\n",
    "#       - log/box-cox transforms on skewed features\n",
    "#       - polynomial features or interaction terms\n",
    "#       - different model (e.g., tree-based)\n",
    "#   - Use cross-validation + grid search for tuning.\n",
    "#\n",
    "# This template gives you:\n",
    "# - A consistent workflow\n",
    "# - A place to drop in dataset-specific logic\n",
    "# - A structure that matches your mental model:\n",
    "#   import → inspect → visualize → clean → encode/scale → split → train → evaluate → refine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300c46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
