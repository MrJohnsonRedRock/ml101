{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d542c4fc",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# #  ML Project Template\n",
    "# \n",
    "# Reusable workflow:\n",
    "# 1. Imports & config\n",
    "# 2. Load data\n",
    "# 3. Inspect & clean\n",
    "# 4. EDA (visualization)\n",
    "# 5. Preprocessing & feature engineering\n",
    "# 6. Train/test split\n",
    "# 7. Model training\n",
    "# 8. Evaluation & residual analysis\n",
    "# 9. Cross-validation\n",
    "# 10. Iteration hooks\n",
    "\n",
    "# %% \n",
    "# 1. IMPORTS & CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot style (optional)\n",
    "plt.style.use(\"default\")\n",
    "sns.set_theme()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ## 2. Load Data\n",
    "# - Adjust file path and loader as needed.\n",
    "# - This cell is the only one that should be very dataset-specific.\n",
    "\n",
    "# 2. LOAD DATA\n",
    "\n",
    "# TODO: Change this to your actual data file\n",
    "DATA_PATH = \"AmesHousing.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Basic Inspection & Sanity Checks\n",
    "# - `info`, `describe`, missing values\n",
    "# - Categorical vs numeric overview\n",
    "\n",
    "# 3. INSPECT DATA\n",
    "\n",
    "print(\"=== INFO ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== DESCRIBE (NUMERIC) ===\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES PER COLUMN ===\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\n=== UNIQUE VALUES PER COLUMN ===\")\n",
    "print(df.nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69055b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Quick EDA: Distributions & Outliers\n",
    "# - Histograms\n",
    "# - Boxplots\n",
    "# - Basic skewness check\n",
    "#\n",
    "# NOTE: Adjust `numeric_cols` list to your dataset.\n",
    "# 4. EDA - DISTRIBUTIONS\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "# Histograms\n",
    "df[numeric_cols].hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for numeric columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "df[numeric_cols].boxplot()\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplots of Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Skewness\n",
    "print(\"\\n=== SKEWNESS ===\")\n",
    "print(df[numeric_cols].skew())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Relationships: Scatter, Correlation, Pairplot\n",
    "# - Use this cell when dataset is not huge.\n",
    "# - Adjust `key_features` to a smaller subset if needed.\n",
    "# 5. EDA - RELATIONSHIPS\n",
    "\n",
    "# TODO: Set your target column\n",
    "TARGET_COL = \"SalePrice\" #This will always be Y, or desired prediction\n",
    "\n",
    "# Choose a few key features for scatter / pairplot\n",
    "key_features = [col for col in numeric_cols if col != TARGET_COL][:4]\n",
    "print(\"Key features for pairplot:\", key_features)\n",
    "\n",
    "if TARGET_COL in df.columns:\n",
    "    # Simple scatter with target if numeric\n",
    "    if np.issubdtype(df[TARGET_COL].dtype, np.number):\n",
    "        for col in key_features:\n",
    "            plt.figure()\n",
    "            plt.scatter(df[col], df[TARGET_COL], alpha=0.5)\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel(TARGET_COL)\n",
    "            plt.title(f\"{col} vs {TARGET_COL}\")\n",
    "            plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "corr = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot (small feature subset)\n",
    "if len(key_features) > 1:\n",
    "    sns.pairplot(df[key_features + [TARGET_COL]].dropna(), corner=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Handle Missing Data & Obvious Cleaning\n",
    "# - Light-touch template. Customize as needed.\n",
    "# - Options: drop rows, impute, custom rules.\n",
    "\n",
    "# 6. CLEANING\n",
    "\n",
    "# Standardize column names to snake_case\n",
    "import re\n",
    "\n",
    "def to_snake(col):\n",
    "    # Replace spaces and hyphens with underscore\n",
    "    col = re.sub(r\"[ -]+\", \"_\", col)\n",
    "\n",
    "    # Insert underscore before capital letters (except first)\n",
    "    # col = re.sub(r\"(?<!^)([A-Z])\", r\"_\\1\", col)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    # col = col.lower()\n",
    "\n",
    "    return col\n",
    "\n",
    "df.columns = [to_snake(col) for col in df.columns]\n",
    "\n",
    "# print(\"Updated column names:\")\n",
    "# print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# Identify missing data\n",
    "missing_summary = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary.head(20))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435646a",
   "metadata": {},
   "source": [
    "6.1 DROP ROWS ONLY WHEN NECESSARY\n",
    "\n",
    "Only drop:\n",
    "\n",
    "rows missing the target\n",
    "\n",
    "rows that are mostly empty\n",
    "\n",
    "rows containing invalid data (e.g., negative square footage)\n",
    "\n",
    "6.2 IMPUTE NUMERIC COLUMNS\n",
    "\n",
    "Why median?\n",
    "\n",
    "Median is robust to outliers\n",
    "Mean gets distorted badly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if there is a positive correlation between Lot_Area and Lot_Frontage\n",
    "\n",
    "sns.scatterplot(x=df[\"Lot_Area\"], y=df[\"Lot_Frontage\"])\n",
    "plt.xscale(\"log\")  # because Lot_Area spans huge ranges\n",
    "plt.show()\n",
    "\n",
    "df[[\"Lot_Area\", \"Lot_Frontage\"]].corr()\n",
    "\n",
    "# There is, so lets impute missing Lot_Frontage values based on Lot_Area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPUTE LOT_FRONTAGE USING LOT_AREA RATIO\n",
    "# ========================================\n",
    "\n",
    "print(\"Missing Lot_Frontage BEFORE:\", df[\"Lot_Frontage\"].isna().sum())\n",
    "\n",
    "# 1. Create missingness flag (always useful for models)\n",
    "df[\"Lot_Frontage_missing\"] = df[\"Lot_Frontage\"].isna().astype(int)\n",
    "\n",
    "# 2. Compute typical depth = Lot_Area / Lot_Frontage\n",
    "#    (only using rows where both values exist)\n",
    "valid = df.dropna(subset=[\"Lot_Frontage\", \"Lot_Area\"])\n",
    "\n",
    "# Avoid divide-by-zero rows\n",
    "valid = valid[valid[\"Lot_Frontage\"] > 0]\n",
    "\n",
    "median_depth = (valid[\"Lot_Area\"] / valid[\"Lot_Frontage\"]).median()\n",
    "print(\"Median lot depth (Lot_Area / Lot_Frontage):\", median_depth)\n",
    "\n",
    "# 3. Impute missing frontage as Lot_Area / median_depth\n",
    "mask_missing = df[\"Lot_Frontage\"].isna()\n",
    "\n",
    "df.loc[mask_missing, \"Lot_Frontage\"] = (\n",
    "    df.loc[mask_missing, \"Lot_Area\"] / median_depth\n",
    ")\n",
    "\n",
    "print(\"Missing Lot_Frontage AFTER:\", df[\"Lot_Frontage\"].isna().sum())\n",
    "print(\"Imputed Lot_Frontage for\", mask_missing.sum(), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7171486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle pool weirdness\n",
    "\n",
    "print(df[\"Pool_QC\"].value_counts(dropna=False))\n",
    "print(df[\"Pool_Area\"].describe())\n",
    "# Impute Pool_QC based on Pool_Area\n",
    "df[\"Has_Pool\"] = (\n",
    "    (df[\"Pool_Area\"] > 0) | df[\"Pool_QC\"].notna()\n",
    ").astype(int)\n",
    "# For rows where we believe there is NO pool, set quality to \"None\"\n",
    "no_pool_mask = (df[\"Has_Pool\"] == 0) & (df[\"Pool_QC\"].isna())\n",
    "df.loc[no_pool_mask, \"Pool_QC\"] = \"None\"\n",
    "print(\"After imputation of Pool_QC based on Pool_Area:\")\n",
    "print(df[\"Pool_QC\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Hassing Misc_Feature, add Boolean flag column\n",
    "# Replace NA with None, strip whitespace\n",
    "\n",
    "print(df[\"Misc_Feature\"].value_counts(dropna=False))\n",
    "df[\"Has_Misc_Feature\"] = df[\"Misc_Feature\"].notna().astype(int)\n",
    "df[\"Misc_Feature\"] = df[\"Misc_Feature\"].fillna(\"None\")\n",
    "df[\"Misc_Feature\"] = df[\"Misc_Feature\"].str.strip()\n",
    "df[\"Misc_Feature\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle Alley\n",
    "print(df[\"Alley\"].value_counts(dropna=False))\n",
    "# ============================\n",
    "# CLEANING: Alley\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Alley\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Boolean flag—does the house have alley access?\n",
    "df[\"Has_Alley\"] = df[\"Alley\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NA with explicit category \"None\"\n",
    "df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace just in case\n",
    "df[\"Alley\"] = df[\"Alley\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Alley\"].value_counts())\n",
    "print(df[\"Has_Alley\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "445ebe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Fence\n",
      "NaN      2358\n",
      "MnPrv     330\n",
      "GdPrv     118\n",
      "GdWo      112\n",
      "MnWw       12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After:\n",
      "Fence\n",
      "None     2358\n",
      "MnPrv     330\n",
      "GdPrv     118\n",
      "GdWo      112\n",
      "MnWw       12\n",
      "Name: count, dtype: int64\n",
      "Has_Fence\n",
      "0    2358\n",
      "1     572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# CLEANING: Fence\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Fence\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Feature flag — does the house have ANY fenced enclosure?\n",
    "df[\"Has_Fence\"] = df[\"Fence\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NaN with explicit category \"None\"\n",
    "df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace (always safe)\n",
    "df[\"Fence\"] = df[\"Fence\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Fence\"].value_counts())\n",
    "print(df[\"Has_Fence\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13183823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Mas_Vnr_Type\n",
      "NaN        1775\n",
      "BrkFace     880\n",
      "Stone       249\n",
      "BrkCmn       25\n",
      "CBlock        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After:\n",
      "Mas_Vnr_Type\n",
      "None       1745\n",
      "BrkFace     880\n",
      "Stone       249\n",
      "BrkCmn       25\n",
      "Unknown       7\n",
      "CBlock        1\n",
      "Name: count, dtype: int64\n",
      "Has_Masonry_Veneer\n",
      "0    1771\n",
      "1    1159\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# CLEANING: Mas_Vnr_Type\n",
    "# ============================\n",
    "\n",
    "# Ai defiiniely help with this one.  Didn't really think to include Masonry Veneer\n",
    "# area as a qualifier for what the data meant.  If 0, NA means None.  If >0, NA means Unknown.\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Feature flag — does the house have a masonry veneer?\n",
    "df[\"Has_Masonry_Veneer\"] = (df[\"Mas_Vnr_Area\"] > 0).astype(int)\n",
    "\n",
    "# 2. Case 1: Area == 0 → definitely None\n",
    "none_mask = (df[\"Mas_Vnr_Area\"] == 0) & (df[\"Mas_Vnr_Type\"].isna())\n",
    "df.loc[none_mask, \"Mas_Vnr_Type\"] = \"None\"\n",
    "\n",
    "# 3. Case 2: Area > 0 but type is missing → ambiguous → \"Unknown\"\n",
    "unknown_mask = (df[\"Mas_Vnr_Area\"] > 0) & (df[\"Mas_Vnr_Type\"].isna())\n",
    "df.loc[unknown_mask, \"Mas_Vnr_Type\"] = \"Unknown\"\n",
    "\n",
    "# 4. Clean whitespace\n",
    "df[\"Mas_Vnr_Type\"] = df[\"Mas_Vnr_Type\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Mas_Vnr_Type\"].value_counts())\n",
    "print(df[\"Has_Masonry_Veneer\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b94f1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Fireplace_Qu\n",
      "NaN    1422\n",
      "Gd      744\n",
      "TA      600\n",
      "Fa       75\n",
      "Po       46\n",
      "Ex       43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After:\n",
      "Fireplace_Qu\n",
      "None    1422\n",
      "Gd       744\n",
      "TA       600\n",
      "Fa        75\n",
      "Po        46\n",
      "Ex        43\n",
      "Name: count, dtype: int64\n",
      "Has_Fireplace\n",
      "1    1508\n",
      "0    1422\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# CLEANING: Fireplace_Qu\n",
    "# ============================\n",
    "\n",
    "print(\"Before:\")\n",
    "print(df[\"Fireplace_Qu\"].value_counts(dropna=False))\n",
    "\n",
    "# 1. Boolean flag — does the house have a fireplace?\n",
    "df[\"Has_Fireplace\"] = df[\"Fireplace_Qu\"].notna().astype(int)\n",
    "\n",
    "# 2. Replace NA with explicit category \"None\"\n",
    "df[\"Fireplace_Qu\"] = df[\"Fireplace_Qu\"].fillna(\"None\")\n",
    "\n",
    "# 3. Clean whitespace\n",
    "df[\"Fireplace_Qu\"] = df[\"Fireplace_Qu\"].str.strip()\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(df[\"Fireplace_Qu\"].value_counts())\n",
    "print(df[\"Has_Fireplace\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e19c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046a7e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After handling Garage_Type:\n",
      "Garage_Type\n",
      "Attchd     1731\n",
      "Detchd      782\n",
      "BuiltIn     186\n",
      "None        157\n",
      "Basment      36\n",
      "2Types       23\n",
      "CarPort      15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle Garage\n",
    "#1.  Intelligently determine the boolean flag for Has_Garage based on available data\n",
    "df[\"Has_Garage\"] = (\n",
    "    (df[\"Garage_Cars\"] > 0) | \n",
    "    (df[\"Garage_Area\"] > 0) | \n",
    "    (df[\"Garage_Type\"].notna())\n",
    ").astype(int)\n",
    "#2 Use the boolean flag to impute missing Garage_Type values\n",
    "# If no garage: type is None\n",
    "df.loc[(df[\"Has_Garage\"] == 0) & (df[\"Garage_Type\"].isna()), \"Garage_Type\"] = \"None\"\n",
    "\n",
    "# If garage exists but type missing: mark Unknown\n",
    "df.loc[(df[\"Has_Garage\"] == 1) & (df[\"Garage_Type\"].isna()), \"Garage_Type\"] = \"Unknown\"\n",
    "print(\"After handling Garage_Type:\")\n",
    "print(df[\"Garage_Type\"].value_counts(dropna=False))\n",
    "\n",
    "#3 Use the boolean flag to impute other Garage-related categorical columns\n",
    "garage_cols = [\"Garage_Finish\", \"Garage_Qual\", \"Garage_Cond\"]\n",
    "\n",
    "for col in garage_cols:\n",
    "    # No garage → None\n",
    "    df.loc[(df[\"Has_Garage\"] == 0) & (df[col].isna()), col] = \"None\"\n",
    "\n",
    "    # Garage exists but value missing → Unknown\n",
    "    df.loc[(df[\"Has_Garage\"] == 1) & (df[col].isna()), col] = \"Unknown\"\n",
    "\n",
    "#4 Deal with Garage_Yr_Blt.  Assume same year if possible.\n",
    "\n",
    "df.loc[df[\"Has_Garage\"] == 0, \"Garage_Yr_Blt\"] = 0\n",
    "\n",
    "df.loc[(df[\"Has_Garage\"] == 1) & (df[\"Garage_Yr_Blt\"].isna()), \"Garage_Yr_Blt\"] = \\\n",
    "    df.loc[(df[\"Has_Garage\"] == 1), \"Year_Built\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21bab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# CLEANING: Basement block\n",
    "# ==================================\n",
    "\n",
    "# 1. Does the house have a basement?\n",
    "df[\"Has_Basement\"] = (\n",
    "    (df[\"Total_Bsmt_SF\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_1\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_2\"] > 0) |\n",
    "    (df[\"Bsmt_Unf_SF\"] > 0)\n",
    ").astype(int)\n",
    "\n",
    "# 2. Finished vs Unfinished booleans\n",
    "df[\"Has_Finished_Basement\"] = (\n",
    "    (df[\"BsmtFin_SF_1\"] > 0) |\n",
    "    (df[\"BsmtFin_SF_2\"] > 0)\n",
    ").astype(int)\n",
    "\n",
    "df[\"Has_Unfinished_Basement\"] = (df[\"Bsmt_Unf_SF\"] > 0).astype(int)\n",
    "\n",
    "# 3. Clean the categorical basement columns\n",
    "basement_cols = [\n",
    "    \"Bsmt_Qual\", \"Bsmt_Cond\", \"BsmtFinType1\", \"BsmtFinType2\"\n",
    "]\n",
    "\n",
    "# 3a. If no basement → fill with \"None\"\n",
    "for col in basement_cols:\n",
    "    df.loc[(df[\"Has_Basement\"] == 0) & (df[col].isna()), col] = \"None\"\n",
    "\n",
    "# 3b. If basement exists but NA → \"Unknown\"\n",
    "for col in basement_cols:\n",
    "    df.loc[(df[\"Has_Basement\"] == 1) & (df[col].isna()), col] = \"Unknown\"\n",
    "\n",
    "# 4. Special cleaning for Bsmt_Exposure\n",
    "# NA means \"No exposure\" IF the house has a basement\n",
    "df.loc[(df[\"Has_Basement\"] == 0), \"Bsmt_Exposure\"] = \"None\"\n",
    "df.loc[(df[\"Has_Basement\"] == 1) & (df[\"Bsmt_Exposure\"].isna()), \"Bsmt_Exposure\"] = \"No\"\n",
    "\n",
    "# 5. Strip whitespace (safety)\n",
    "for col in [\"Bsmt_Qual\", \"Bsmt_Cond\", \"BsmtFinType1\", \"BsmtFinType2\", \"Bsmt_Exposure\"]:\n",
    "    df[col] = df[col].astype(str).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "# Example: drop rows with missing target\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "# Example: simple numeric impute with median (optional – often better in a pipeline)\n",
    "# for col in numeric_cols:\n",
    "#     df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Example: simple categorical impute with mode\n",
    "# cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "# for col in cat_cols:\n",
    "#     df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"After basic cleaning, shape:\", df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ce6de8",
   "metadata": {},
   "source": [
    "6.3 IMPUTE CATEGORICAL COLUMNS\n",
    "\n",
    "Most common strategies:\n",
    "\n",
    "Mode (most frequent value)\n",
    "\n",
    "Works well when missing data is small.\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\"Unknown\" Category\n",
    "This is actually more honest than pretending you know.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df[col] = df[col].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025877d",
   "metadata": {},
   "source": [
    "6.4 FLAG THE MISSINGNESS (Power move)\n",
    "\n",
    "A missing value indicator can be extremely predictive.\n",
    "\n",
    "Example:\n",
    "\n",
    "A missing basement quality often means “no basement”\n",
    "\n",
    "A missing fireplace quality often means “no fireplace”\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col + \"_was_missing\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n",
    "This adds search-light columns that say:\n",
    "\n",
    "1 = was missing\n",
    "\n",
    "0 = was present\n",
    "\n",
    "Models love this.\n",
    "\n",
    "6.5 CLEAN OBVIOUS BAD VALUES\n",
    "\n",
    "Examples:\n",
    "\n",
    "Square footage cannot be negative.\n",
    "\n",
    "Lot area cannot be zero.\n",
    "\n",
    "Quality ratings must be one of the known categories.\n",
    "\n",
    "df['Gr_Liv_Area'] = df['Gr_Liv_Area'].clip(lower=0)\n",
    "\n",
    "6.6 NORMALIZE TEXT DATA (easy mistakes)\n",
    "\n",
    "Common cleaning:\n",
    "\n",
    "df[col] = df[col].str.strip().str.lower()\n",
    "df[col] = df[col].str.replace('-', '_')\n",
    "\n",
    "\n",
    "Cleaning avoids:\n",
    "\n",
    "duplicates (“Ex”, “ex”, “ EX”)\n",
    "\n",
    "weird Unicode\n",
    "\n",
    "inconsistent punctuation\n",
    "\n",
    "6.8 Final Check: Data Must Be Fully Clean\n",
    "\n",
    "After imputation:\n",
    "\n",
    "print(df.isna().sum().sum())   # should be 0\n",
    "\n",
    "\n",
    "If NOT zero → model will crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 7. Define Features (X) and Target (y)\n",
    "# - Select feature columns explicitly.\n",
    "# - Split numeric vs categorical.\n",
    "# - This is where you decide what the model can \"see.\"\n",
    "\n",
    "# 7. FEATURE / TARGET SETUP\n",
    "\n",
    "# TODO: decide which columns are features\n",
    "feature_cols = [c for c in df.columns if c != TARGET_COL]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 8. Preprocessing: Encoding & Scaling\n",
    "# - Numeric: StandardScaler\n",
    "# - Categorical: OneHotEncoder\n",
    "# - All wrapped in a ColumnTransformer + Pipeline\n",
    "\n",
    "# 8. PREPROCESSOR\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example model: Linear Regression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Full pipeline: preprocessing + model\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", regressor)\n",
    "])\n",
    "\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 9. Train/Test Split\n",
    "# - Typical split: 80/20 or 70/30.\n",
    "# - Randomized with fixed `random_state` for reproducibility.\n",
    "\n",
    "# 9. TRAIN / TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Train the Model\n",
    "# - Fit the pipeline on training data.\n",
    "# 10. TRAIN MODEL\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 11. Evaluation on Train and Test Sets\n",
    "# - R², MAE, RMSE\n",
    "# - Compare train vs test for over/underfitting.\n",
    "\n",
    "# 11. EVALUATION\n",
    "\n",
    "def regression_metrics(y_true, y_pred, label=\"\"):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print()\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "regression_metrics(y_train, y_pred_train, label=\"Train\")\n",
    "regression_metrics(y_test, y_pred_test, label=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 12. Residual Analysis (Train Set)\n",
    "# - Check assumptions: linearity, homoscedasticity, normality.\n",
    "# %%\n",
    "# 12. RESIDUALS\n",
    "\n",
    "train_residuals = y_train - y_pred_train\n",
    "\n",
    "# Residuals vs predicted\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_pred_train, train_residuals, alpha=0.5)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted (Train)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predicted (Train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(train_residuals, kde=True)\n",
    "plt.title(\"Residuals Distribution (Train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 13. Cross Validation (Optional but Recommended)\n",
    "# - K-Fold CV for more robust estimation.\n",
    "# - Uses the full pipeline (preprocess + model) inside CV.\n",
    "\n",
    "# 13. CROSS VALIDATION\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf, scoring=\"r2\")\n",
    "\n",
    "print(\"CV R² scores:\", cv_scores)\n",
    "print(\"CV R² mean:\", cv_scores.mean())\n",
    "print(\"CV R² std:\", cv_scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acaac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 14. TODO: Iteration Hooks\n",
    "# - If metrics are poor:\n",
    "#   - Revisit EDA, transformations, feature engineering.\n",
    "#   - Consider:\n",
    "#       - log/box-cox transforms on skewed features\n",
    "#       - polynomial features or interaction terms\n",
    "#       - different model (e.g., tree-based)\n",
    "#   - Use cross-validation + grid search for tuning.\n",
    "#\n",
    "# This template gives you:\n",
    "# - A consistent workflow\n",
    "# - A place to drop in dataset-specific logic\n",
    "# - A structure that matches your mental model:\n",
    "#   import → inspect → visualize → clean → encode/scale → split → train → evaluate → refine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300c46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
